{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5a25eb2-ba55-4290-bf89-eb718b6562e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b79b237b-0dcf-4988-b1c4-66da584fef7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "def replace_numbers(text):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "\n",
    "def remove_whitespaces(text):\n",
    "    return text.strip()\n",
    "\n",
    "def stem_words(words):\n",
    "    \"\"\"Stem words in text\"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "def text2words(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def normalize_text( text):\n",
    "    text = remove_punctuation(text)\n",
    "    text = replace_numbers(text)\n",
    "    words = text2words(text)\n",
    "   \n",
    "    words = stem_words(words)# Eitherstem ovocar lemmatize\n",
    "   \n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e40f71ed-a4d7-4306-814f-5bc0db265f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readstr(Path): \n",
    "    f = open(Path, \"r\",encoding='UTF8')\n",
    "    str1 = \"\" \n",
    "    for x in f:\n",
    "        str1=str1+x\n",
    "    return  str1 \n",
    "\n",
    "def get_count(word_l):\n",
    "    word_count_dict = {}  \n",
    "    word_count_dict = Counter(word_l) \n",
    "    return word_count_dict\n",
    "def get_probs(word_count_dict):\n",
    "    probs = {} \n",
    "    m = sum(word_count_dict.values())\n",
    "    for key in word_count_dict.keys():\n",
    "        probs[key] = word_count_dict[key] / m\n",
    "    ### END CODE HERE ###\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "265fddbc-7a3e-4b7e-94c9-587992e09a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "Str = readstr('dataset.txt')\n",
    "wold_clean = normalize_text(Str)  # this will be your new vocabulary#print(wold_cleaan)\n",
    "#ودي هي الفوكاب بس متكرر فيها بعد الكلمات\n",
    "vocab = set(wold_clean)  # this will be your new vocabulary\n",
    "word_count_dict = get_count(wold_clean)#دي فيها عدد مرات ضهور كلمه معينه\n",
    "print(word_count_dict.get('العلم',0))\n",
    "probs = get_probs(word_count_dict)#دي بتحسب الاحتمال بتاع كل كلمه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72e85d7c-cf11-4729-aa58-a1ccb6d36459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delete_letter(word, verbose=False):\n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "    for c in range(len(word)):\n",
    "        split_l.append((word[:c],word[c:]))\n",
    "    for a,b in split_l:\n",
    "        delete_l.append(a+b[1:])          \n",
    "    if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
    "\n",
    "    return delete_l\n",
    "\n",
    "def insert_letter(word, verbose=False):\n",
    "    letters=\"ابتثجحخدذرزسشصضطظعغفقلكمونيةؤءئ\"\n",
    "   # letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "    for c in range(len(word)+1):\n",
    "        split_l.append((word[0:c],word[c:]))\n",
    "    insert_l = [ a + l + b for a,b in split_l for l in letters]\n",
    "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
    "    return insert_\n",
    "\n",
    "\n",
    "def switch_letter(word, verbose=False):\n",
    "\n",
    "    def swap(c, i, j):\n",
    "        c = list(c)\n",
    "        c[i], c[j] = c[j], c[i]\n",
    "        return ''.join(c)    \n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "    len_word=len(word)\n",
    "    ### START CODE HERE ###\n",
    "    for c in range(len_word):\n",
    "        split_l.append((word[:c],word[c:]))\n",
    "    switch_l = [a + b[1] + b[0] + b[2:] for a,b in split_l if len(b) >= 2]      \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
    "    return switch_l\n",
    "def replace_letter(word, verbose=False):\n",
    "    letters=\"ابتثجحخدذرزسشصضطظعغفقلكمونيةؤءئ\"\n",
    "    replace_l = []\n",
    "    split_l = []\n",
    "    for c in range(len(word)):\n",
    "        split_l.append((word[0:c],word[c:]))\n",
    "    replace_l = [a + l + (b[1:] if len(b)> 1 else '') for a,b in split_l if b for l in letters]\n",
    "    replace_set=set(replace_l)    \n",
    "    replace_set.remove(word)\n",
    "    replace_l = sorted(list(replace_set))\n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
    "    return replace_l\n",
    "\n",
    "def edit_one_letter(word, allow_switches = True):\n",
    "    edit_one_set = set()\n",
    "    edit_one_set.update(delete_letter(word))\n",
    "    if allow_switches:\n",
    "        edit_one_set.update(switch_letter(word))\n",
    "    edit_one_set.update(replace_letter(word))\n",
    "    edit_one_set.update(insert_letter(word))\n",
    "    return edit_one_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bdf240-3502-4617-bdcf-2f184ce59604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bf3ed62-8ed0-4d5b-b3e4-7b656c667115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a855a84-25cb-4040-b032-7170bb18da70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5423213c-82ac-41bb-b50a-ece59cc40d69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c520a63e-3b88-4ec7-ae26-d5dddd838529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrections(word, probs, vocab, n=2, verbose = False):\n",
    "    suggestions = []\n",
    "    n_best = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    suggestions = list((word in vocab and word) or edit_one_letter(word).intersection(vocab) or edit_two_letters(word).intersection(vocab))\n",
    "    n_best = [[s,probs[s]] for s in list(reversed(suggestions))]\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    if verbose: print(\"suggestions = \", suggestions)\n",
    "\n",
    "    return n_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "67eda89c-3488-4eed-b3f5-d6f227f92a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word 0: فينا, probability 0.000151\n",
      "word 1: دينا, probability 0.000076\n",
      "word 2: كمينا, probability 0.000076\n",
      "word 3: حينا, probability 0.000076\n",
      "word 4: منا, probability 0.000302\n"
     ]
    }
   ],
   "source": [
    "my_word = \"مينا\"\n",
    "tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=False)\n",
    "for i, word_prob in enumerate(tmp_corrections):\n",
    "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7df492-4f91-4726-af0e-40dc45d1169d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
